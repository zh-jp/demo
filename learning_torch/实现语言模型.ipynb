{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义基本工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def elapsed(sec):   # 计算时间函数\n",
    "    if sec < 60:\n",
    "        return str(sec) + 'sec'\n",
    "    elif sec < (60*60):\n",
    "        return str(sec/60) + 'min'\n",
    "    else:\n",
    "        return str(sec*(60*60)) + 'hr'\n",
    "    \n",
    "training_file = 'data/wordstest.txt' # 定义样本文件\n",
    "\n",
    "def readalltxt(txt_files):   # 处理中文\n",
    "    labels = []\n",
    "    for txt_file in txt_files:\n",
    "        target = get_ch_label(txt_file)\n",
    "        labels.append(target)\n",
    "    return labels\n",
    "\n",
    "def get_ch_label(txt_file):     # 获取样本中的汉字\n",
    "    labels = \"\"\n",
    "    with open(txt_file, 'rb') as f:\n",
    "        for label in f:\n",
    "            labels = labels +label.decode('utf-8')\n",
    "    return labels\n",
    "\n",
    "# 将汉字转为向量，支持文件和内存对象里的汉字转换\n",
    "def get_ch_label_v(txt_file, word_num_map, txt_label=None): \n",
    "    words_size = len(word_num_map)\n",
    "    to_num = lambda word: word_num_map.get(word, words_size)\n",
    "    if txt_file != None:\n",
    "        txt_label = get_ch_label(txt_file)\n",
    "    labels_vector = list(map(to_num, txt_file))\n",
    "    return labels_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 样本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data...\n",
      "样本长度： 200\n",
      "字表大小： 101\n"
     ]
    }
   ],
   "source": [
    "training_data = get_ch_label(training_file)\n",
    "print('Loaded training data...')\n",
    "\n",
    "print('样本长度：', len(training_data))\n",
    "counter = Counter(training_data)\n",
    "words = sorted(counter)\n",
    "words_size = len(words)\n",
    "word_num_map = dict(zip(words, range(words_size)))\n",
    "\n",
    "print('字表大小：',words_size)\n",
    "wordlabel = get_ch_label_v(training_file, word_num_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 构建循环神经网络（RNN）模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRURNN(torch.nn.Module):\n",
    "    def __init__(self, word_size, embed_dim, hidden_dim, output_size, num_layers) -> None:\n",
    "        super(GRURNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = torch.nn.Embedding(word_size,embed_dim)\n",
    "        self.gru = torch.nn.GRU(input_size=embed_dim, hidden_size=hidden_dim, \n",
    "                                num_layers=num_layers, bidirectional=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim*2, output_size)\n",
    "\n",
    "    def forward(self, features, hidden):\n",
    "        embedded = self.embed(features.view(1,-1))\n",
    "        output, hidden = self.gru(embedded.view(1,1,-1), hidden)\n",
    "        output = self.attention(output)\n",
    "        output = self.fc(output.view(1,-1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_zero_state(self):\n",
    "        init_hidden = torch.zeros(self.num_layers*2, 1,\n",
    "                                  self.hidden_dim).to(DEVICE)\n",
    "        return init_hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 实例化模型，并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# 实例化模型\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m GRURNN(words_size, EMBEDDING_DIM, HIDDEN_DIM, words_size, NUM_LAYERS)\n\u001b[1;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[0;32m      8\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# 定义预测函数\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pj1\\lib\\site-packages\\torch\\nn\\modules\\module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    897\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 899\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pj1\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pj1\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 593\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    594\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pj1\\lib\\site-packages\\torch\\nn\\modules\\module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 897\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# 定义参数，训练模型\n",
    "EMBEDDING_DIM = 10  # 定义词嵌入维度\n",
    "HIDDEN_DIM = 20      # 定义隐藏层维度\n",
    "NUM_LAYERS = 1      # 定义层数\n",
    "# 实例化模型\n",
    "model = GRURNN(words_size, EMBEDDING_DIM, HIDDEN_DIM, words_size, NUM_LAYERS)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# 定义预测函数\n",
    "def evaluate(model, prime_str, predict_len, temperature=0.8):\n",
    "    hidden = model.init_zero_state().to(DEVICE)\n",
    "    predicted = ''\n",
    "\n",
    "    # 处理输入语义\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_str[p], hidden)     # 将输入文字和状态传入模型\n",
    "        predicted += words[prime_str[p]]\n",
    "    inp = prime_str[-1]     # 获得输入字符\n",
    "    predicted += words[inp]\n",
    "    # 按指定长度输出预测字符\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden) # 将输入字符和状态传入模型\n",
    "        # 从多项式分布中采样\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        inp = torch.multinomial(output_dist, 1)[0]  # 获取采样中的结果\n",
    "        predicted += words[inp]         # 将索引转成汉字并保存到字符串中\n",
    "    return predicted # 将输入字符和预测字符一起返回\n",
    "\n",
    "# 定义参数训练模型\n",
    "training_iters = 5000\n",
    "display_step = 1000\n",
    "n_input = 4\n",
    "step = 0\n",
    "offset = random.randint(0, n_input+1)\n",
    "end_offset = n_input + 1\n",
    "\n",
    "while step < training_iters:    # 按照迭代次数训练模型\n",
    "    start_time = time.time()    # 计算起始时间\n",
    "    # 随机取一个位置偏移\n",
    "    if offset > (len(training_data) - end_offset):\n",
    "        offset = random.randint(0, n_input+1)\n",
    "    # 制作输入样本\n",
    "    inwords = wordlabel[offset:offset+n_input]\n",
    "    inwords = np.reshape(np.array(inwords), [n_input, -1, 1])\n",
    "    # 制作标签样本\n",
    "    out_onehot = wordlabel[offset+1:offset+n_input+1]\n",
    "    hidden = model.init_zero_state()   # 将RNN初始状态清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    inputs = torch.LongTensor(inwords).to(DEVICE)\n",
    "    targets = torch.LongTensor(out_onehot).to(DEVICE)\n",
    "    for c in range(n_input):    # 按照输入长度依次将样本输入模型进行预测\n",
    "        outputs, hidden = model(inputs[c], hidden)\n",
    "        loss += F.cross_entropy(outputs, targets[c].view(1))\n",
    "    \n",
    "    loss /= n_input\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 输出日志\n",
    "    with torch.set_grad_enabled(False):\n",
    "        if (step+1)%display_step == 0:\n",
    "            print(f'Time elapsed: {(time.time() - start_time)/60:.4f} min')\n",
    "            print(f'step {step+1} | Loss {loss.item():.2f}\\n\\n')\n",
    "            with torch.no_grad():\n",
    "                print(evaluate(model, inputs, 32), '\\n')\n",
    "            print(50*'=')\n",
    "    step += 1\n",
    "    offset += (n_input+1)\n",
    "print('Finished!')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a2ba024e8b74661af8ab6e95599756a59d5ec2a34e482eaba93c7adfdb10e92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
